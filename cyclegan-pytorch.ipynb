{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"name":"cyclegan-pytorch.ipynb","provenance":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"_kg_hide-input":false,"id":"DIlKeF9f9TqC","executionInfo":{"status":"error","timestamp":1604992867493,"user_tz":480,"elapsed":62887,"user":{"displayName":"Lawrence Quesada","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDfi5ZMUHec5oABIqu-Gh8jDLncpZUMsEadkSem7Y=s64","userId":"14131790862529985455"}},"outputId":"4db0f79d-73ad-4f17-8737-b5e3f9c1f2f6","colab":{"base_uri":"https://localhost:8080/","height":469}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import torch.utils.data as data\n","import random\n","from torchvision import transforms\n","\n","from PIL import Image\n","\n","import os , itertools\n","print(os.listdir(\"/content/drive/My Drive/Dataset/UTKFace\"))\n","\n","import matplotlib.pyplot as plt\n","\n","params = {\n","    'batch_size':1,\n","    'input_size':256,\n","    'resize_scale':286,\n","    'crop_size':256,\n","    'fliplr':True,\n","    #model params\n","    'num_epochs':100,\n","    'decay_epoch':100,\n","    'ngf':32,   #number of generator filters\n","    'ndf':64,   #number of discriminator filters\n","    'num_resnet':6, #number of resnet blocks\n","    'lrG':0.0002,    #learning rate for generator\n","    'lrD':0.0002,    #learning rate for discriminator\n","    'beta1':0.5 ,    #beta1 for Adam optimizer\n","    'beta2':0.999 ,  #beta2 for Adam optimizer\n","    'lambdaA':10 ,   #lambdaA for cycle loss\n","    'lambdaB':10  ,  #lambdaB for cycle loss\n","}\n","\n","data_dir = '/content/drive/My Drive/Dataset/UTKFace'\n","def to_np(x):\n","    return x.data.cpu().numpy()\n","def plot_train_result(real_image, gen_image, recon_image, epoch, save=False,  show=True, fig_size=(15, 15)):\n","    fig, axes = plt.subplots(2, 3, figsize=fig_size)\n","    imgs = [to_np(real_image[0]), to_np(gen_image[0]), to_np(recon_image[0]),\n","            to_np(real_image[1]), to_np(gen_image[1]), to_np(recon_image[1])]\n","    for ax, img in zip(axes.flatten(), imgs):\n","        ax.axis('off')\n","        #ax.set_adjustable('box-forced')\n","        # Scale to 0-255\n","        img = img.squeeze()\n","        img = (((img - img.min()) * 255) / (img.max() - img.min())).transpose(1, 2, 0).astype(np.uint8)\n","        ax.imshow(img, cmap=None, aspect='equal')\n","    plt.subplots_adjust(wspace=0, hspace=0)\n","\n","    title = 'Epoch {0}'.format(epoch + 1)\n","    fig.text(0.5, 0.04, title, ha='center')\n","\n","    # save figure\n","    if save:\n","        save_fn = 'Result_epoch_{:d}'.format(epoch+1) + '.png'\n","        plt.savefig(save_fn)\n","\n","    if show:\n","        plt.show()\n","    else:\n","        plt.close()\n","\n","class ImagePool():\n","    def __init__(self, pool_size):\n","        self.pool_size = pool_size\n","        if self.pool_size > 0:\n","            self.num_imgs = 0\n","            self.images = []\n","\n","    def query(self, images):\n","        if self.pool_size == 0:\n","            return images\n","        return_images = []\n","        for image in images.data:\n","            image = torch.unsqueeze(image, 0)\n","            if self.num_imgs < self.pool_size:\n","                self.num_imgs = self.num_imgs + 1\n","                self.images.append(image)\n","                return_images.append(image)\n","            else:\n","                p = random.uniform(0, 1)\n","                if p > 0.5:\n","                    random_id = random.randint(0, self.pool_size-1)\n","                    tmp = self.images[random_id].clone()\n","                    self.images[random_id] = image\n","                    return_images.append(tmp)\n","                else:\n","                    return_images.append(image)\n","        return_images = Variable(torch.cat(return_images, 0))\n","        return return_images\n","        \n","class DatasetFromFolder(data.Dataset):\n","    def __init__(self, image_dir, subfolder='train', transform=None, resize_scale=None, crop_size=None, fliplr=False):\n","        super(DatasetFromFolder, self).__init__()\n","        self.input_path = os.path.join(image_dir, subfolder)\n","        self.image_filenames = [x for x in sorted(os.listdir(self.input_path))]\n","        self.transform = transform\n","        \n","        self.resize_scale = resize_scale\n","        self.crop_size = crop_size\n","        self.fliplr = fliplr\n","\n","    def __getitem__(self, index):\n","        # Load Image\n","        img_fn = os.path.join(self.input_path, self.image_filenames[index])\n","        img = Image.open(img_fn).convert('RGB')\n","\n","        # preprocessing\n","        if self.resize_scale:\n","            img = img.resize((self.resize_scale, self.resize_scale), Image.BILINEAR)\n","\n","        if self.crop_size:\n","            x = random.randint(0, self.resize_scale - self.crop_size + 1)\n","            y = random.randint(0, self.resize_scale - self.crop_size + 1)\n","            img = img.crop((x, y, x + self.crop_size, y + self.crop_size))\n","        if self.fliplr:\n","            if random.random() < 0.5:\n","                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        return img\n","\n","    def __len__(self):\n","        return len(self.image_filenames)\n","\n","\n","class ConvBlock(torch.nn.Module):\n","    def __init__(self,input_size,output_size,kernel_size=3,stride=2,padding=1,activation='relu',batch_norm=True):\n","        super(ConvBlock,self).__init__()\n","        self.conv = torch.nn.Conv2d(input_size,output_size,kernel_size,stride,padding)\n","        self.batch_norm = batch_norm\n","        self.bn = torch.nn.InstanceNorm2d(output_size)\n","        self.activation = activation\n","        self.relu = torch.nn.ReLU(True)\n","        self.lrelu = torch.nn.LeakyReLU(0.2,True)\n","        self.tanh = torch.nn.Tanh()\n","    def forward(self,x):\n","        if self.batch_norm:\n","            out = self.bn(self.conv(x))\n","        else:\n","            out = self.conv(x)\n","        \n","        if self.activation == 'relu':\n","            return self.relu(out)\n","        elif self.activation == 'lrelu':\n","            return self.lrelu(out)\n","        elif self.activation == 'tanh':\n","            return self.tanh(out)\n","        elif self.activation == 'no_act':\n","            return out\n","            \n","class DeconvBlock(torch.nn.Module):\n","    def __init__(self,input_size,output_size,kernel_size=3,stride=2,padding=1,output_padding=1,activation='relu',batch_norm=True):\n","        super(DeconvBlock,self).__init__()\n","        self.deconv = torch.nn.ConvTranspose2d(input_size,output_size,kernel_size,stride,padding,output_padding)\n","        self.batch_norm = batch_norm\n","        self.bn = torch.nn.InstanceNorm2d(output_size)\n","        self.activation = activation\n","        self.relu = torch.nn.ReLU(True)\n","    def forward(self,x):\n","        if self.batch_norm:\n","            out = self.bn(self.deconv(x))\n","        else:\n","            out = self.deconv(x)\n","        if self.activation == 'relu':\n","            return self.relu(out)\n","        elif self.activation == 'lrelu':\n","            return self.lrelu(out)\n","        elif self.activation == 'tanh':\n","            return self.tanh(out)\n","        elif self.activation == 'no_act':\n","            return out\n","\n","class ResnetBlock(torch.nn.Module):\n","    def __init__(self,num_filter,kernel_size=3,stride=1,padding=0):\n","        super(ResnetBlock,self).__init__()\n","        conv1 = torch.nn.Conv2d(num_filter,num_filter,kernel_size,stride,padding)\n","        conv2 = torch.nn.Conv2d(num_filter,num_filter,kernel_size,stride,padding)\n","        bn = torch.nn.InstanceNorm2d(num_filter)\n","        relu = torch.nn.ReLU(True)\n","        pad = torch.nn.ReflectionPad2d(1)\n","        \n","        self.resnet_block = torch.nn.Sequential(\n","            pad,\n","            conv1,\n","            bn,\n","            relu,\n","            pad,\n","            conv2,\n","            bn\n","            )\n","    def forward(self,x):\n","        out = self.resnet_block(x)\n","        return out\n","        \n","class Generator(torch.nn.Module):\n","    def __init__(self,input_dim,num_filter,output_dim,num_resnet):\n","        super(Generator,self).__init__()\n","        \n","        #Reflection padding\n","        self.pad = torch.nn.ReflectionPad2d(3)\n","        #Encoder\n","        self.conv1 = ConvBlock(input_dim,num_filter,kernel_size=7,stride=1,padding=0)\n","        self.conv2 = ConvBlock(num_filter,num_filter*2)\n","        self.conv3 = ConvBlock(num_filter*2,num_filter*4)\n","        #Resnet blocks\n","        self.resnet_blocks = []\n","        for i in range(num_resnet):\n","            self.resnet_blocks.append(ResnetBlock(num_filter*4))\n","        self.resnet_blocks = torch.nn.Sequential(*self.resnet_blocks)\n","        #Decoder\n","        self.deconv1 = DeconvBlock(num_filter*4,num_filter*2)\n","        self.deconv2 = DeconvBlock(num_filter*2,num_filter)\n","        self.deconv3 = ConvBlock(num_filter,output_dim,kernel_size=7,stride=1,padding=0,activation='tanh',batch_norm=False)\n","    \n","    def forward(self,x):\n","        #Encoder\n","        enc1 = self.conv1(self.pad(x))\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        #Resnet blocks\n","        res = self.resnet_blocks(enc3)\n","        #Decoder\n","        dec1 = self.deconv1(res)\n","        dec2 = self.deconv2(dec1)\n","        out = self.deconv3(self.pad(dec2))\n","        return out\n","    \n","    def normal_weight_init(self,mean=0.0,std=0.02):\n","        for m in self.children():\n","            if isinstance(m,ConvBlock):\n","                torch.nn.init.normal_(m.conv.weight,mean,std)\n","            if isinstance(m,DeconvBlock):\n","                torch.nn.init.normal_(m.deconv.weight,mean,std)\n","            if isinstance(m,ResnetBlock):\n","                torch.nn.init.normal_(m.conv.weight,mean,std)\n","                torch.nn.init.constant_(m.conv.bias,0)\n","\n","class Discriminator(torch.nn.Module):\n","    def __init__(self,input_dim,num_filter,output_dim):\n","        super(Discriminator,self).__init__()\n","        conv1 = ConvBlock(input_dim,num_filter,kernel_size=4,stride=2,padding=1,activation='lrelu',batch_norm=False)\n","        conv2 = ConvBlock(num_filter,num_filter*2,kernel_size=4,stride=2,padding=1,activation='lrelu')\n","        conv3 = ConvBlock(num_filter*2,num_filter*4,kernel_size=4,stride=2,padding=1,activation='lrelu')\n","        conv4 = ConvBlock(num_filter*4,num_filter*8,kernel_size=4,stride=1,padding=1,activation='lrelu')\n","        conv5 = ConvBlock(num_filter*8,output_dim,kernel_size=4,stride=1,padding=1,activation='no_act',batch_norm=False)\n","        self.conv_blocks = torch.nn.Sequential(\n","            conv1,\n","            conv2,\n","            conv3,\n","            conv4,\n","            conv5\n","            )\n","    def forward(self,x):\n","        out = self.conv_blocks(x)\n","        return out\n","        \n","    def normal_weight_init(self,mean=0.0,std=0.02):\n","        for m in self.children():\n","            if isinstance(m,ConvBlock):\n","                torch.nn.init.normal_(m.conv.weight.data,mean,std)\n","\n","transform = transforms.Compose([\n","    transforms.Resize(size=params['input_size']),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n","])\n","train_data_A = DatasetFromFolder(data_dir, subfolder='trainA_Male', transform=transform,\n","                                resize_scale=params['resize_scale'], crop_size=params['crop_size'], fliplr=params['fliplr'])\n","train_data_loader_A = torch.utils.data.DataLoader(dataset=train_data_A, batch_size=params['batch_size'], shuffle=True)\n","train_data_B = DatasetFromFolder(data_dir, subfolder='trainB_Female', transform=transform,\n","                                resize_scale=params['resize_scale'], crop_size=params['crop_size'], fliplr=params['fliplr'])\n","train_data_loader_B = torch.utils.data.DataLoader(dataset=train_data_B, batch_size=params['batch_size'], shuffle=True)\n","#Load test data\n","test_data_A = DatasetFromFolder(data_dir, subfolder='testA_Male', transform=transform)\n","test_data_loader_A = torch.utils.data.DataLoader(dataset=test_data_A, batch_size=params['batch_size'], shuffle=False)\n","test_data_B = DatasetFromFolder(data_dir, subfolder='testB_Female', transform=transform)\n","test_data_loader_B = torch.utils.data.DataLoader(dataset=test_data_B, batch_size=params['batch_size'], shuffle=False)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Get specific test images\n","test_real_A_data = train_data_A.__getitem__(11).unsqueeze(0) # Convert to 4d tensor (BxNxHxW)\n","test_real_B_data = train_data_B.__getitem__(91).unsqueeze(0)\n","#print(test_real_A_data)\n","#Build Model \n","G_A = Generator(3, params['ngf'], 3, params['num_resnet']).cuda() # input_dim, num_filter, output_dim, num_resnet\n","G_B = Generator(3, params['ngf'], 3, params['num_resnet']).cuda()\n","\n","D_A = Discriminator(3, params['ndf'], 1).cuda() # input_dim, num_filter, output_dim\n","D_B = Discriminator(3, params['ndf'], 1).cuda()\n","\n","G_A.normal_weight_init(mean=0.0, std=0.02)\n","G_B.normal_weight_init(mean=0.0, std=0.02)\n","D_A.normal_weight_init(mean=0.0, std=0.02)\n","D_B.normal_weight_init(mean=0.0, std=0.02)\n","\n","\n","G_optimizer = torch.optim.Adam(itertools.chain(G_A.parameters(), G_B.parameters()), lr=params['lrG'], betas=(params['beta1'], params['beta2']))\n","D_A_optimizer = torch.optim.Adam(D_A.parameters(), lr=params['lrD'], betas=(params['beta1'], params['beta2']))\n","D_B_optimizer = torch.optim.Adam(D_B.parameters(), lr=params['lrD'], betas=(params['beta1'], params['beta2']))\n","\n","MSE_Loss = torch.nn.MSELoss().cuda()\n","L1_Loss = torch.nn.L1Loss().cuda()\n","\n","# # Training GAN\n","D_A_avg_losses = []\n","D_B_avg_losses = []\n","G_A_avg_losses = []\n","G_B_avg_losses = []\n","cycle_A_avg_losses = []\n","cycle_B_avg_losses = []\n","\n","# Generated image pool\n","num_pool = 50\n","fake_A_pool = ImagePool(num_pool)\n","fake_B_pool = ImagePool(num_pool)\n","\n","step = 0\n","for epoch in range(params['num_epochs']):\n","    D_A_losses = []\n","    D_B_losses = []\n","    G_A_losses = []\n","    G_B_losses = []\n","    cycle_A_losses = []\n","    cycle_B_losses = []\n","    \n","    # Learing rate decay \n","    if(epoch + 1) > params['decay_epoch']:\n","        D_A_optimizer.param_groups[0]['lr'] -= params['lrD'] / (params['num_epochs'] - params['decay_epoch'])\n","        D_B_optimizer.param_groups[0]['lr'] -= params['lrD'] / (params['num_epochs'] - params['decay_epoch'])\n","        G_optimizer.param_groups[0]['lr'] -= params['lrG'] / (params['num_epochs'] - params['decay_epoch'])\n","        \n","    \n","    # training \n","    for i, (real_A, real_B) in enumerate(zip(train_data_loader_A, train_data_loader_B)):\n","        \n","        # input image data\n","        real_A = real_A.to(device)\n","        real_B = real_B.to(device)\n","        \n","        # -------------------------- train generator G --------------------------\n","        # A --> B\n","        fake_B = G_A(real_A)\n","        D_B_fake_decision = D_B(fake_B)\n","        G_A_loss = MSE_Loss(D_B_fake_decision, Variable(torch.ones(D_B_fake_decision.size()).cuda()))\n","        \n","        # forward cycle loss\n","        recon_A = G_B(fake_B)\n","        cycle_A_loss = L1_Loss(recon_A, real_A) * params['lambdaA']\n","        \n","        # B --> A\n","        fake_A = G_B(real_B)\n","        D_A_fake_decision = D_A(fake_A)\n","        G_B_loss = MSE_Loss(D_A_fake_decision, Variable(torch.ones(D_A_fake_decision.size()).cuda()))\n","        \n","        # backward cycle loss\n","        recon_B = G_A(fake_A)\n","        cycle_B_loss = L1_Loss(recon_B, real_B) * params['lambdaB']\n","        \n","        # Back propagation\n","        G_loss = G_A_loss + G_B_loss + cycle_A_loss + cycle_B_loss\n","        G_optimizer.zero_grad()\n","        G_loss.backward()\n","        G_optimizer.step()\n","        \n","        \n","        # -------------------------- train discriminator D_A --------------------------\n","        D_A_real_decision = D_A(real_A)\n","        D_A_real_loss = MSE_Loss(D_A_real_decision, Variable(torch.ones(D_A_real_decision.size()).cuda()))\n","        \n","        fake_A = fake_A_pool.query(fake_A)\n","        \n","        D_A_fake_decision = D_A(fake_A)\n","        D_A_fake_loss = MSE_Loss(D_A_fake_decision, Variable(torch.zeros(D_A_fake_decision.size()).cuda()))\n","        \n","        # Back propagation\n","        D_A_loss = (D_A_real_loss + D_A_fake_loss) * 0.5\n","        D_A_optimizer.zero_grad()\n","        D_A_loss.backward()\n","        D_A_optimizer.step()\n","        \n","        # -------------------------- train discriminator D_B --------------------------\n","        D_B_real_decision = D_B(real_B)\n","        D_B_real_loss = MSE_Loss(D_B_real_decision, Variable(torch.ones(D_B_fake_decision.size()).cuda()))\n","        \n","        fake_B = fake_B_pool.query(fake_B)\n","        \n","        D_B_fake_decision = D_B(fake_B)\n","        D_B_fake_loss = MSE_Loss(D_B_fake_decision, Variable(torch.zeros(D_B_fake_decision.size()).cuda()))\n","        \n","        # Back propagation\n","        D_B_loss = (D_B_real_loss + D_B_fake_loss) * 0.5\n","        D_B_optimizer.zero_grad()\n","        D_B_loss.backward()\n","        D_B_optimizer.step()\n","        \n","        # ------------------------ Print -----------------------------\n","        # loss values\n","        D_A_losses.append(D_A_loss.item())\n","        D_B_losses.append(D_B_loss.item())\n","        G_A_losses.append(G_A_loss.item())\n","        G_B_losses.append(G_B_loss.item())\n","        cycle_A_losses.append(cycle_A_loss.item())\n","        cycle_B_losses.append(cycle_B_loss.item())\n","\n","        if i%100 == 0:\n","            print('Epoch [%d/%d], Step [%d/%d], D_A_loss: %.4f, D_B_loss: %.4f, G_A_loss: %.4f, G_B_loss: %.4f'\n","                  % (epoch+1, params['num_epochs'], i+1, len(train_data_loader_A), D_A_loss.item(), D_B_loss.item(), G_A_loss.item(), G_B_loss.item()))\n","            \n","        step += 1\n","        \n","    D_A_avg_loss = torch.mean(torch.FloatTensor(D_A_losses))\n","    D_B_avg_loss = torch.mean(torch.FloatTensor(D_B_losses))\n","    G_A_avg_loss = torch.mean(torch.FloatTensor(G_A_losses))\n","    G_B_avg_loss = torch.mean(torch.FloatTensor(G_B_losses))\n","    cycle_A_avg_loss = torch.mean(torch.FloatTensor(cycle_A_losses))\n","    cycle_B_avg_loss = torch.mean(torch.FloatTensor(cycle_B_losses))\n","\n","    # avg loss values for plot\n","    D_A_avg_losses.append(D_A_avg_loss.item())\n","    D_B_avg_losses.append(D_B_avg_loss.item())\n","    G_A_avg_losses.append(G_A_avg_loss.item())\n","    G_B_avg_losses.append(G_B_avg_loss.item())\n","    cycle_A_avg_losses.append(cycle_A_avg_loss.item())\n","    cycle_B_avg_losses.append(cycle_B_avg_loss.item())\n","    \n","    # Show result for test image\n","    test_real_A = test_real_A_data.cuda()\n","    test_fake_B = G_A(test_real_A)\n","    test_recon_A = G_B(test_fake_B)\n","\n","    test_real_B = test_real_B_data.cuda()\n","    test_fake_A = G_B(test_real_B)\n","    test_recon_B = G_A(test_fake_A)\n","\n","    plot_train_result([test_real_A, test_real_B], [test_fake_B, test_fake_A], [test_recon_A, test_recon_B],\n","                            epoch, save=True)\n","\n","all_losses = pd.DataFrame()\n","all_losses['D_A_avg_losses'] = D_A_avg_losses\n","all_losses['D_B_avg_losses'] = D_B_avg_losses\n","all_losses['G_A_avg_losses'] = G_A_avg_losses\n","all_losses['G_B_avg_losses'] = G_B_avg_losses\n","all_losses['cycle_A_avg_losses'] = cycle_A_avg_losses\n","all_losses['cycle_B_avg_losses'] = cycle_B_avg_losses\n","all_losses.to_csv('avg_losses',index=False)\n"," "],"execution_count":3,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-3fe0ceebdbda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    277\u001b[0m ])\n\u001b[1;32m    278\u001b[0m train_data_A = DatasetFromFolder(data_dir, subfolder='trainA_Male', transform=transform,\n\u001b[0;32m--> 279\u001b[0;31m                                 resize_scale=params['resize_scale'], crop_size=params['crop_size'], fliplr=params['fliplr'])\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0mtrain_data_loader_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m train_data_B = DatasetFromFolder(data_dir, subfolder='trainB_Female', transform=transform,\n","\u001b[0;32m<ipython-input-3-3fe0ceebdbda>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_dir, subfolder, transform, resize_scale, crop_size, fliplr)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetFromFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/drive/My Drive/Dataset/UTKFace/trainA_Male'"]}]},{"cell_type":"code","metadata":{"id":"6FdLox_29er6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZeEE6FWg-M45","executionInfo":{"status":"ok","timestamp":1604992791732,"user_tz":480,"elapsed":30248,"user":{"displayName":"Lawrence Quesada","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDfi5ZMUHec5oABIqu-Gh8jDLncpZUMsEadkSem7Y=s64","userId":"14131790862529985455"}},"outputId":"e93c1251-b1b1-4367-d4c3-28288fee8557","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XnPVg3qU-N21"},"source":[""],"execution_count":null,"outputs":[]}]}