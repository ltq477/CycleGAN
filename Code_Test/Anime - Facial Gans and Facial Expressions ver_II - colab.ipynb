{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1144,
     "status": "ok",
     "timestamp": 1604454182205,
     "user": {
      "displayName": "Lawrence Quesada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDfi5ZMUHec5oABIqu-Gh8jDLncpZUMsEadkSem7Y=s64",
      "userId": "14131790862529985455"
     },
     "user_tz": 480
    },
    "id": "CZ9zgk9GnzMA",
    "outputId": "fedc7313-4de5-4be8-a6b5-7ef379165bda"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZANtNG8O9yku"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, we will attempt to greate a Generative Adversarial Network (GAN) in order to manipulate facial expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQq79p3Q9ykw"
   },
   "source": [
    "Our first step is to load the neccessary libraries we will be using for the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1823,
     "status": "ok",
     "timestamp": 1604454182920,
     "user": {
      "displayName": "Lawrence Quesada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDfi5ZMUHec5oABIqu-Gh8jDLncpZUMsEadkSem7Y=s64",
      "userId": "14131790862529985455"
     },
     "user_tz": 480
    },
    "id": "ay4pmFE69ykx"
   },
   "outputs": [],
   "source": [
    "#Loading the neccessary libraries\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "#from skimage import io\n",
    "#from pathlib import Path\n",
    "#from PIL import Image\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.animation as animation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpSznCUs9yk2"
   },
   "source": [
    "We will now create a variable which points to our local directory. We create these variables as shortcut so we will not have to type the entire directory everytime needed. Take note that the image dataset/directory is located in a different folder than the python notebook files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1604454308992,
     "user": {
      "displayName": "Lawrence Quesada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDfi5ZMUHec5oABIqu-Gh8jDLncpZUMsEadkSem7Y=s64",
      "userId": "14131790862529985455"
     },
     "user_tz": 480
    },
    "id": "BSLm4az3-0Sv"
   },
   "outputs": [],
   "source": [
    "windows_path = 'Data/AnimeFaces'\n",
    "colab_path = f'/content/drive/My Drive/Thinkful/CapstoneIV/Dataset'\n",
    "basepath = windows_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1604454309780,
     "user": {
      "displayName": "Lawrence Quesada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDfi5ZMUHec5oABIqu-Gh8jDLncpZUMsEadkSem7Y=s64",
      "userId": "14131790862529985455"
     },
     "user_tz": 480
    },
    "id": "s6-ur4blnsPv",
    "outputId": "7678e532-09ce-4c08-9a94-2428d0d0c254"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/AnimeFaces'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('animation.gif', writer='imagemagick',fps=5)\n",
    "Image(url='animation.gif')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Anime - Facial Gans and Facial Expressions ver_II - colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
